{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CSCI 303\n",
    "# Introduction to Data Science\n",
    "<p/>\n",
    "\n",
    "## Convolutional Neural Networks\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/3288/1*uAeANQIOQPqWZnnuH-VEyw.jpeg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks (CNN)\n",
    "\n",
    "- CNNs are NNs with a specialized architecture that makes them suited for **computer vision tasks**.\n",
    "- We want algorithms that can detect an object, regardless of where it in the image (\"**translational invariance**\")\n",
    "- CNNs are **hierarchical**\n",
    " - **Early layers** help detect **simple image features** (lines, arcs, corners, blobs)\n",
    " - **Higher layers** help detect more **complex image features** (ears, eyes, wheels, chrome)\n",
    "- Translation invariance and hierarchy concepts are inspired by neuroscience (to some degree)\n",
    "\n",
    "### Assumption: Object have hierarchical representations\n",
    "\n",
    "<img src=\"https://pathmind.com/images/wiki/feature_hierarchy.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional kernels\n",
    "\n",
    "### Most \"layers\" of a CNN are \"convolutional layers\"\n",
    "### Convolution: Filtering of an image with a small \"kernel\" that looks like a useful features (line, arc, etc.)\n",
    "- Each neuron within a layer has an **kernel of weights** that are **arranged in a 2D matrix**.\n",
    "- There are identical neurons (all have the same kernel), also arranged in a 2D pattern.\n",
    "  - In practice, we don't really have an array of neurons in a 2D pattern.\n",
    "  - Instead, **the kernel is shifted across the input image (or input from the previous layer) and applied to the inputs that it overlaps with. This is the so-called convolution operation.**\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/35737777/68632479-95c61f80-04e6-11ea-80b2-2e86a4fcc258.jpg\" width=\"600\">\n",
    "\n",
    "### Many different kernels (filters) are used/applied in a given layer, e.g.,\n",
    "- a kernel for an up-down line\n",
    "- a kernel for a left-right line\n",
    "- a kernel for a point/blob\n",
    "- etc.\n",
    "\n",
    "### So, a layer that takes in an MxN 3-channel (R,G,B) image may have C different kernels, and thus output an MxNxC array.\n",
    "\n",
    "<img src=\"https://ds055uzetaobb.cloudfront.net/brioche/uploads/MDyKhb5tXY-1_hbp1vrfewnareprrlnxtqq2x.png?width=1200\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Max) Pooling\n",
    "\n",
    "- A hierarchy model implies that:\n",
    "  - More complex **features found at higher layers** of the model will often be **spatially larger**.\n",
    "  - Because features at layer L+1 are made up of features at layer L, not of pixel-level features, the **resolution at layer L+1 can be lower than that at layer L**.\n",
    "  - To lower the resolution, we compute the maximum value over small areas and **replace the area with that max value** (e.g., replace a 2x2 patch with a 1x1 value).\n",
    "  \n",
    "<img src=\"https://computersciencewiki.org/images/8/8a/MaxpoolSample2.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A complete CNN model\n",
    "\n",
    "## Basic CNN models commonly have a sequence of layers like this, although the number of layers may varying widely, depending on the comlexity of the task/images.\n",
    " - Convolutional layer with ReLU activation\n",
    " - Max-pooling layer\n",
    " - \n",
    " - Convolutional layer with ReLU activation\n",
    " - Max-pooling layer\n",
    " - \n",
    " - ...\n",
    " - Convolutional layer with ReLU activation\n",
    " - Max-pooling layer\n",
    " - \n",
    " - Flatten the MxNxC array into a MNCx1 array\n",
    " - \n",
    " - Dense layer with ReLU\n",
    " - \n",
    " - Dense layer without ReLU\n",
    " \n",
    "\n",
    "## Example figure 1\n",
    "- 3D shape of kernels is not highly apparent in this figure\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/3288/1*uAeANQIOQPqWZnnuH-VEyw.jpeg\" width=\"800\">\n",
    "\n",
    "## Example figure 2\n",
    "- 3D shape of kernels is clearing in this figure, but\n",
    "- Max-pooling is not highly apparent in this figure (but can be inferred)\n",
    "\n",
    "<img src=\"https://www.mdpi.com/remotesensing/remotesensing-09-00848/article_deploy/html/images/remotesensing-09-00848-g001.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fun with OpenAI Microscope\n",
    "### What features are some of the neurons in a CNN **sensitive** to?\n",
    "https://openai.com/blog/microscope/\n",
    "\n",
    "### <span style=\"color: red;\">Low level features in the AlexNet model:</span>\n",
    "\n",
    "![](low_level_features.png)\n",
    "\n",
    "### <span style=\"color: red;\">High level features in the AlexNet model:</span>\n",
    "\n",
    "![](high_level_features.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other CNN vision applications\n",
    "\n",
    "## <span style=\"color: red;\">Object localization and segmentation</span>\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1280/1*Mj8WKVKf_RpiAsX3SC1ZdQ.png\" width=\"700\">\n",
    "\n",
    "\n",
    "## <span style=\"color: red;\">Art: Neural style transfer</span>\n",
    "\n",
    "<img src=\"https://jvns.ca/images/neural-style.png\" width=\"700\">\n",
    "\n",
    "\n",
    "## <span style=\"color: red;\">Image generation: Generative Adversarial Networks (GAN)</span>\n",
    "### <span style=\"color: red;\">Two networks trained simultaneously</span>\n",
    " - **Generator** network tries to create realistic-looking image from noise inputs\n",
    " - **Discriminator** network tries to distinguish real images for synthetic ones from the generator\n",
    " \n",
    "<img src=\"https://pathmind.com/images/wiki/GANs.png\" width=\"700\">\n",
    "\n",
    "<img src=\"https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/05/Plot-of-Randomly-Generated-Faces-Using-the-Loaded-GAN-Model.png\" width=\"700\">\n",
    "\n",
    "\n",
    "## <span style=\"color: red;\">\"Deep Fakes\"</span>\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/4276/1*qCGMkRffdJ2-KSzQ3G2PfA.jpeg\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building CNNs\n",
    "\n",
    "**Tensorflow** has great tools for building and training CNNs (and so does PyTorch).  \n",
    "We'll be exploring Tensorflow CNN construction and training in a separate assignment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
